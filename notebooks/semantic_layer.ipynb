{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09dcb388",
   "metadata": {},
   "source": [
    "# SEMANTIC_LAYER.ipynb \n",
    "# Semantic-Based Clustering Method for Hierarchy Engine\n",
    "\n",
    "---\n",
    "## Overview\n",
    "- Docstring and Imports\n",
    "- K Selection Helper Function\n",
    "- Core Semantic-Based Clustering Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce01e8",
   "metadata": {},
   "source": [
    "## 1 - Docstring and Imports\n",
    "The Semantic Layer utilizes string labels to perform embedding-based clustering based on the meaning of the words within the label. \n",
    "\n",
    "Embedding-based semantic clustering is especially effective when structured category-like data exists, or if existing text data columns are dense and consistently formatted. In these scenarios, semantic clustering works fast and produces results that are easy to understand/validate. Within the context of Hierarchy, the Semantic Layer clusters groups to organize large numbers of narrow categories underneath broad umbrellas. \n",
    "\n",
    "The Semantic Layer is constructed using the sklearn library. Specifically, KMeans is used as the actual clustering agent. NumPy and Pandas are used for data management, and annotations/type hints are incorporated for clarity. Additionally, two useful functions from `.text_utils` are imported as helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c52e93",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# core/semantic_layer.py\n",
    "\n",
    "\"\"\"\n",
    "This file implements the Semantic Layer.\n",
    "\n",
    "The Semantic Layer groups unique string labels using embedding-based\n",
    "clustering to identify semantically similar categories, then maps those\n",
    "cluster assignments back onto the original dataframe. Each semantic\n",
    "cluster is also given a human-readable name derived from its member\n",
    "labels using TF-IDF keyword scoring.\n",
    "\n",
    "This layer is typically applied to categorical or hierarchical label\n",
    "columns (e.g., category names) and is intended to sit above or alongside\n",
    "attribute-based clustering layers.\n",
    "\n",
    "Public API used by the hierarchy engine:\n",
    "\n",
    "    build_semantic_layer(\n",
    "        df,\n",
    "        *,\n",
    "        input_label_col,\n",
    "        n_clusters,\n",
    "        output_prefix,\n",
    "        random_state=42\n",
    "    ) -> pd.DataFrame\n",
    "        Returns a copy of df with two new columns:\n",
    "        `{output_prefix}_id` containing integer semantic cluster IDs\n",
    "        and `{output_prefix}_name` containing human-readable cluster names.\n",
    "\n",
    "Internal helpers:\n",
    "\n",
    "    _choose_k(n_items, k_min=2, k_max=12) -> int\n",
    "        Heuristic for selecting a reasonable number of clusters when\n",
    "        an explicit value is not provided.\n",
    "\"\"\"\n",
    "\n",
    "# Type hints\n",
    "from __future__ import annotations\n",
    "\n",
    "# External dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn dependencies\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Internal dependencies\n",
    "from .text_utils import build_embeddings_for_labels, tfidf_cluster_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ba5b2",
   "metadata": {},
   "source": [
    "# 2 - K Heuristic\n",
    "This helper function determines the optimal k value for KMeans using the following heuristic: k is set to the squareroot of the number of items within the category. This value is clipped to prevent over-fragmentation and ensure that there is more than one cluster. The function takes the following arguments: an integer `n_items`, an integer `k_min`, and an integer `k_max`. In practice, `n_items` is the number of items within a category, while `k_min` and `k_max` are lower and upper bounds for k with default values 2 and 12, respectively. \n",
    "\n",
    "Line-by-line breakdown:\n",
    "- If the number of items within a cluster is 1 or less, then the function returns `k=1` (cannot be more than one cluster in this scenario).\n",
    "- k is initialized as the squareroot of the number of items within the category. \n",
    "- k is clipped as the greater value between `k_min` and `min(k_max, k)`.\n",
    "- k is again clipped as the lesser value between k and `n_items`.\n",
    "- The clipped k is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7b309",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def _choose_k(n_items: int, k_min: int = 2, k_max: int = 12):\n",
    "    if n_items <= 1:\n",
    "        return 1\n",
    "    k = int(np.sqrt(n_items))\n",
    "    k = max(k_min, min(k_max, k))\n",
    "    k = min(k, n_items)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8885ba1f",
   "metadata": {},
   "source": [
    "# 3 Core Semantic-Based Clustering Logic\n",
    "\n",
    "This function contains the semantic-layer construction. The function accepts the following arguments: a Pandas DataFrame `df`, a string `input_label_col`, an optional integer `n_clusters`, a string `output_prefix`, and an integer `random_state`. In practice, `df` is the complete original dataset, `input_lable_col` is a column containing text labels to embed and cluster, `n_clusters` is an explicit cluster amount (can be None), `output_prefix` is a prefix added to output columns, and `random_state` is a seed for reproducibility. The function returns a Pandas DataFrame, which is the original dataset with an additional column for cluster assignments.\n",
    "\n",
    "Due to the size of the function, it will be broken down into sections and explained line by line. This first section is simply the function definition and docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e7784",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_semantic_layer(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    input_label_col: str,\n",
    "    n_clusters: int | None,\n",
    "    output_prefix: str,\n",
    "    random_state: int = 42,\n",
    ") -> pd.DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb8053",
   "metadata": {},
   "source": [
    "# 3.1 - Preparation\n",
    "\n",
    "This section creates a safe copy of the input dataset, generates a cleaned Series of labels using 'input_label_col', and creates a sorted list of unique, non-empty labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f40f280",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    df = df.copy()\n",
    "\n",
    "    labels = (\n",
    "        df[input_label_col]\n",
    "        .fillna(\"\")\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "    )\n",
    "    unique_labels = sorted({v for v in labels if v})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1dd367",
   "metadata": {},
   "source": [
    "# 3.2 Degeneration Guard\n",
    "\n",
    "This section contains a failsafe, assigning every item to a single cluster named \"All\" and returning early in the instance that there are no usable labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00dcad4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    if not unique_labels:\n",
    "        df[f\"{output_prefix}_id\"] = 0\n",
    "        df[f\"{output_prefix}_name\"] = \"All\"\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a2e64c",
   "metadata": {},
   "source": [
    "# 3.3 Decide k\n",
    "\n",
    "This section evaluates k using the non-public function `_choose_k` based on the number of unique labels. However, if the number of desired clusters is None or less than 1, then k is initialized to `min(max(1, n_clusters), len(unique_labels))`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e12f30",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # k\n",
    "    if n_clusters is None or n_clusters < 1:\n",
    "        k = _choose_k(len(unique_labels))\n",
    "    else:\n",
    "        k = min(max(1, n_clusters), len(unique_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43900088",
   "metadata": {},
   "source": [
    "# 3.4 Embeddings\n",
    "\n",
    "This section uses the imported function `build_embeddings_for_labels` to construct embeddings stored as `emb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615c9c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # embeddings\n",
    "    emb = build_embeddings_for_labels(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70097b14",
   "metadata": {},
   "source": [
    "# 3.5 k-Means Clustering\n",
    "\n",
    "This section actually conducts the semantic clustering algorithm.\n",
    "\n",
    "Line-by-line breakdown:\n",
    "- If k is less than or equal to 1, the raw clusters are initialized as the NumPy zero array (everything is assigned to one cluster)\n",
    "- Otherwise, KMeans is initialized using `n_clusters`, and the `fit_predict` method is used with `emb` as the input parameter. The result is stored as `cluster_raw`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a016d78",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    if k <= 1:\n",
    "        cluster_raw = np.zeros(len(unique_labels), dtype=int)\n",
    "    else:\n",
    "        km = KMeans(n_clusters=k, random_state=random_state, n_init=\"auto\")\n",
    "        cluster_raw = km.fit_predict(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4b24d",
   "metadata": {},
   "source": [
    "# 3.6 Normalization\n",
    "\n",
    "This section normalizes the cluster IDs such that the first cluster is assigned the value \"1\" instead of \"0\". \n",
    "\n",
    "Line-by-line breakdown:\n",
    "- The distinct cluster IDs KMeans produced (as integers) is sorted and stored as `uniq_raw`.\n",
    "- The \"1-based\" mapping is stored as `raw2id`.\n",
    "- A dictionary mapping of labels and cluster IDs is stored as `label_to_cid`.\n",
    "- Each row/item of the original dataset is assigned a cluster using the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7781deb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # normalize IDs (1..K)\n",
    "    uniq_raw = sorted(set(int(x) for x in cluster_raw))\n",
    "    raw2id = {raw: i + 1 for i, raw in enumerate(uniq_raw)}\n",
    "\n",
    "    label_to_cid = {\n",
    "        lbl: raw2id[int(raw)]\n",
    "        for lbl, raw in zip(unique_labels, cluster_raw)\n",
    "    }\n",
    "\n",
    "    df[f\"{output_prefix}_id\"] = labels.map(label_to_cid).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113255b",
   "metadata": {},
   "source": [
    "# 3.7 Naming\n",
    "\n",
    "This section generates human-readable cluster names.\n",
    "\n",
    "Line-by-line breakdown:\n",
    "- A dictionary `clusters` is initialized, which will store cluster assignments in the format `cid: item`, where `cid` is the numerical cluster ID, and item is the row/group of rows assigned to the associated cluster ID. \n",
    "- A dictionary `name_map` is initialized.\n",
    "- Iterate through each cluster assignment (in a group of 180 items, there are 180 total cluster assignments).\n",
    "- For each iteration, attempt to store the return of `tfidf_cluster_labels(members)` as a value for the current `cid` (`name_map` key).\n",
    "- If the function fails, then the first three labels of a cluster assignment are taken and joined together to name the cluster.\n",
    "- After iteration concludes, assign the name mapping as a new column in the original dataframe and return.\n",
    "\n",
    "Note: `tfidf_cluster_labels` can be found in the notebook breakdown for `text_utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2edac1d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # names\n",
    "    clusters = {}\n",
    "    for lbl, cid in label_to_cid.items():\n",
    "        clusters.setdefault(cid, []).append(lbl)\n",
    "\n",
    "    name_map = {}\n",
    "    for cid, members in clusters.items():\n",
    "        try:\n",
    "            name_map[cid] = tfidf_cluster_label(members)\n",
    "        except:\n",
    "            name_map[cid] = \" / \".join(members[:3])\n",
    "\n",
    "    df[f\"{output_prefix}_name\"] = df[f\"{output_prefix}_id\"].map(name_map).astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a01582",
   "metadata": {},
   "source": [
    "# NOTE: WHY TF-IDF?\n",
    "\n",
    "TF-IDF treats each label (a product category, customer segment, or something similar) as a **document**, which is then split into **tokens** (individual words within each label). TF-IDF then measures the **term frequency**, calculates **inverse document frequency** (log(total_docs / docs_containing_token)), and multiplies both values together (TF * IDF) to identify words that are common inside the cluster AND rare outside of the cluster. This works well with wide, sparse datasets where many tokens are globally rare and locally dense. TF-IDF is also fast and cheap, which works well with the Streamlit application. Hierarchies are rebuilt within the application based on the user's desired edits, so naming needs to be performed quickly and efficiently to prevent long load times and crashing.  \n",
    "\n",
    "Future versions of this project will experiment with LLMs, which are powerful but expensive. One solution is to use TF-IDF primarily, and optionally use LLM's for refinement. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
